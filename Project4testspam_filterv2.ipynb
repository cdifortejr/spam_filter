{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1MwainAtTY4EwUwymjybzpkRrVEv2Writ","authorship_tag":"ABX9TyM4Fbo41TvIq7W2hcKB6TYn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"MIrDFJRmX3yd","executionInfo":{"status":"ok","timestamp":1745776651798,"user_tz":240,"elapsed":14377,"user":{"displayName":"Christopher DiForte","userId":"04513728717067840016"}}},"outputs":[],"source":["!cp -r /content/drive/MyDrive/AImodels/spam_modelv2 /content/"]},{"cell_type":"code","source":["!ls /content/spam_modelv2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PQgeyTPZXV_","executionInfo":{"status":"ok","timestamp":1745776661231,"user_tz":240,"elapsed":114,"user":{"displayName":"Christopher DiForte","userId":"04513728717067840016"}},"outputId":"929da595-feda-4de8-f7f8-7d17cb0fa07f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["config.json\t   special_tokens_map.json  tokenizer.json\n","model.safetensors  tokenizer_config.json    vocab.txt\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"/content/spam_modelv2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"/content/spam_modelv2\")\n","\n","model.eval()  # Set to inference mode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFas3z3DZdIV","executionInfo":{"status":"ok","timestamp":1745776699719,"user_tz":240,"elapsed":25404,"user":{"displayName":"Christopher DiForte","userId":"04513728717067840016"}},"outputId":"17f5b3eb-6566-4dd8-e5e7-90d1c5b9d5dc"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): DistilBertSdpaAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import torch\n","\n","def predict_spam(text):\n","    # 1. Tokenize the input text\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","\n","    # 2. Move inputs to same device as model (handles GPU/CPU)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","    # 3. Run model in no-gradient mode (faster, safer)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # 4. Get predicted class (0 = Not Spam, 1 = Spam)\n","    logits = outputs.logits\n","    predicted_class = torch.argmax(logits, dim=1).item()\n","\n","    # 5. Return human-readable result\n","    if predicted_class == 1:\n","        return \"Spam ðŸš¨\"\n","    else:\n","        return \"Not Spam âœ…\""],"metadata":{"id":"EMjDDJNzZgWt","executionInfo":{"status":"ok","timestamp":1745776802464,"user_tz":240,"elapsed":23,"user":{"displayName":"Christopher DiForte","userId":"04513728717067840016"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(predict_spam(\"Congratulations! You've won a free cruise!\"))\n","print(predict_spam(\"Hey, can you send me the homework answers?\"))\n","print(predict_spam(\"Limited offer! Get rich quick!\"))\n","print(predict_spam(\"Let's meet at the coffee shop at 3 PM.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTqAM4uuZ7to","executionInfo":{"status":"ok","timestamp":1745776820602,"user_tz":240,"elapsed":1011,"user":{"displayName":"Christopher DiForte","userId":"04513728717067840016"}},"outputId":"ad3278a7-eb42-43dc-e6ce-7278897dae08"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Spam ðŸš¨\n","Not Spam âœ…\n","Not Spam âœ…\n","Not Spam âœ…\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"I0O2qHnmaDzd"},"execution_count":null,"outputs":[]}]}